{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependencies\n",
    "# import pandas as pd\n",
    "# from proxy_requests import ProxyRequests\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup as soup\n",
    "\n",
    "def get_all_match_data(page):\n",
    "    match_data = get_general_match_data(page)\n",
    "    \n",
    "    relevant_data = page.findAll(\"div\",{\"id\":\"content\"})\n",
    "    home_data,home_id = get_team_data(relevant_data,\"home\")\n",
    "    away_data,away_id = get_team_data(relevant_data,\"away\")\n",
    "    \n",
    "    # Each is a list of dictionaries, each dict is a row of df\n",
    "    list_of_series = []\n",
    "    for d in home_data:\n",
    "        d[\"id\"] = home_id\n",
    "        series = pd.Series(d)\n",
    "        list_of_series.append(series)\n",
    "    for d in away_data:\n",
    "        d[\"id\"] = away_id\n",
    "        series = pd.Series(d)\n",
    "        list_of_series.append(series)\n",
    "    df = pd.DataFrame(list_of_series)\n",
    "    \n",
    "    match_data_duplicated = {}\n",
    "    for key in match_data.keys():\n",
    "        item = match_data[key]\n",
    "        match_data_duplicated[key] = [item]*len(df)\n",
    "        \n",
    "    df_match_data = pd.DataFrame(match_data_duplicated)\n",
    "    \n",
    "    df_final = pd.concat([df,df_match_data],axis=1)\n",
    "    return df_final\n",
    "\n",
    "def get_general_match_data(page):\n",
    "    relevant_data = page.findAll(\"div\",{\"class\":\"scorebox\"})[0]\n",
    "    divs = relevant_data.findAll(\"div\",recursive=False)\n",
    "    home_data = divs[0]\n",
    "    away_data = divs[1]\n",
    "    generic_data = divs[2]\n",
    "    d = {}\n",
    "    \n",
    "    d[\"home_name\"] = str(home_data.find(\"a\").text)\n",
    "    d[\"home_score\"] = int(home_data.find(\"div\",{\"class\":\"score\"}).text)\n",
    "    d[\"home_xg\"] = float(home_data.find(\"div\",{\"class\":\"score_xg\"}).text)\n",
    "    d[\"home_manager\"] = str(home_data.find(\"div\",{\"class\":\"datapoint\"}).text.split(\": \")[-1])\n",
    "\n",
    "    d[\"away_name\"] = str(away_data.find(\"a\").text)\n",
    "    d[\"away_score\"] = int(away_data.find(\"div\",{\"class\":\"score\"}).text)\n",
    "    d[\"away_xg\"] = float(away_data.find(\"div\",{\"class\":\"score_xg\"}).text)\n",
    "    d[\"away_manager\"] = str(away_data.find(\"div\",{\"class\":\"datapoint\"}).text.split(\": \")[-1])\n",
    "    \n",
    "    d[\"date\"] = str(generic_data.find(\"a\").text)\n",
    "    d[\"time\"] = str(generic_data.find(\"span\").text.split(\" (\")[0])\n",
    "    d[\"matchweek\"] = int(str(generic_data.findAll(\"div\")[1].text.split(\" (\")[1].split(\" \")[-1])[:-1])\n",
    "    d[\"stadium\"] = str(generic_data.findAll(\"small\")[1].text)\n",
    "    spans = generic_data.findAll(\"span\",{\"style\":\"display:inline-block\"})\n",
    "    d[\"ref\"] = str(spans[0].text.split(\" (\")[0])\n",
    "    d[\"var_ref\"] = str(spans[-1].text.split(\" (\")[0])\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_team_data(team_wrapper,side):\n",
    "    all_tables = team_wrapper[0].findAll(\"div\",{\"class\":\"table_wrapper tabbed\"})\n",
    "    #print(all_tables[0])\n",
    "    if side == \"home\":\n",
    "        table = all_tables[0].find(\"div\",{\"class\":\"table_container current\"})\n",
    "    elif side == \"away\":\n",
    "        table = all_tables[1].find(\"div\",{\"class\":\"table_container current\"})\n",
    "        \n",
    "    team_id_original = str(table[\"id\"])\n",
    "#     print()\n",
    "#     print()\n",
    "#     print(team_id_original)\n",
    "    team_id = team_id_original.split(\"_\")[2]\n",
    "#     print()\n",
    "#     print()\n",
    "#     print(team_id)\n",
    "    if side == \"home\":\n",
    "        table = all_tables[0]\n",
    "    elif side == \"away\":\n",
    "        table = all_tables[1]\n",
    "    \n",
    "    \n",
    "    summary_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_summary\"}).tbody\n",
    "    summary = read_table_data(summary_html)\n",
    "    \n",
    "    passing_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_passing\"}).tbody\n",
    "    passing = read_table_data(passing_html)\n",
    "    \n",
    "    passing_types_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_passing_types\"}).tbody\n",
    "    passing_types = read_table_data(passing_types_html)\n",
    "    \n",
    "    defense_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_defense\"}).tbody\n",
    "    defense = read_table_data(defense_html)\n",
    "    \n",
    "    possession_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_possession\"}).tbody\n",
    "    possession = read_table_data(possession_html)\n",
    "    \n",
    "    misc_html = table.find(\"div\",{\"id\":\"div_stats_\" + team_id + \"_misc\"}).tbody\n",
    "    misc = read_table_data(misc_html)\n",
    "    \n",
    "    output = combine_team_data([summary,passing,passing_types,defense,possession,misc])\n",
    "    return output,team_id\n",
    "    \n",
    "def read_table_data(table_html):\n",
    "    all_player_data = []\n",
    "    player_html_list = table_html.findAll(\"tr\")\n",
    "    for player_html in player_html_list:\n",
    "        player_data = read_player_table_data(player_html)\n",
    "        all_player_data.append(player_data)\n",
    "    # all_player_data is a list of dicts, 1 dict per player of their summary data\n",
    "    return all_player_data\n",
    "\n",
    "def read_player_table_data(player_html):\n",
    "    a = {}\n",
    "    a[\"name\"] = player_html.th.a.text\n",
    "    inner_data = player_html.findAll(\"td\")\n",
    "    a[\"pos\"] = inner_data[2].text\n",
    "    a[\"age\"] = inner_data[3].text.split(\"-\")[0]\n",
    "    for i in range(4,len(inner_data)):\n",
    "        a[str(inner_data[i][\"data-stat\"])] = inner_data[i].text\n",
    "    return a\n",
    "\n",
    "def combine_team_data(datasets):\n",
    "    data_by_player = {}\n",
    "    # First create dict key for each player name\n",
    "    for d in datasets[0]:\n",
    "        data_by_player[d[\"name\"]] = []\n",
    "    # Go through each dataset and update data_by_player\n",
    "    for dataset in datasets:\n",
    "        # Go through each player data and add to data_by_player dict of lists\n",
    "        for i in range(len(dataset)):\n",
    "            player_dict = dataset[i]\n",
    "            player_name = player_dict[\"name\"]\n",
    "            data_by_player[player_name] += [player_dict]\n",
    "    \n",
    "    # Now each entry in data_by_player is a list of dictionaries of data points\n",
    "    output_list = []\n",
    "    for key in data_by_player.keys():\n",
    "        p = data_by_player[key]\n",
    "        merged_data = {**p[0],**p[1],**p[2],**p[3],**p[4],**p[5]}\n",
    "        output_list += [merged_data]\n",
    "        \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
